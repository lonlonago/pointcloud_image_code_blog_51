#  First, the principle of the algorithm 

   The depth camera can obtain the distance information from the object to the camera, and can calculate the 3D camera coordinates of the pixel according to the distance information to generate a point cloud. The calculation formula is: in the formula, it is the depth value, the unit is meters; it is the scaling multiple of the depth value; it is the pixel coordinate, which is the 3D point cloud coordinate corresponding to the pixel; it is the focal length of the camera, which is the optical center of the camera, which is the so-called internal reference. The pose of the camera is also called the external parameter of the camera, which will change with the camera movement. Knowing the internal parameter can convert the depth image into a point cloud, and knowing the external parameter can splice the point clouds generated by the depth maps measured at different positions of the same object into a complete point cloud of ground objects. 

#  Code implementation 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574526017
  ```  
#  III. Display of results 

 ![avatar]( 158b5fdbf530486ba06c4f4bd9907f4c.png) 

 1. Depth image  

 ![avatar]( 00791849d6b341a18f926c21c123e11a.png) 

 2. Point cloud  

